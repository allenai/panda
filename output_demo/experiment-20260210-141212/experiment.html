<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Comparison of Three Large Language Models on Basic Arithmetic: Evaluating Responses to "What is 2 + 2?"</title>
    <style>
              body {
	              font-family: 'Arial', sans-serif;
	              margin: 20px;
	              line-height: 1.6;
	          }

        header {
            text-align: center;
            margin-bottom: 20px;
        }

        h1 {
            color: #333;
        }

        h2 {
            color: #444;
        }

        address {
            margin-top: 20px;
            font-style: normal;
        }

        section {
            margin-bottom: 30px;
        }

        summary {
            font-weight: bold;
            margin-bottom: 10px;
        }

        pre {
            white-space: pre-wrap;
        }
    </style>
</head>
<body>

    <header>
        <h1>Comparison of Three Large Language Models on Basic Arithmetic: Evaluating Responses to "What is 2 + 2?"</h1>
        <i>PANDA</i><br>
        <i>Allen Institute for AI, Seattle, WA</i></br>
	<i>02-10-2026 14:13:41</i><br>
	<tt>panda@allenai.org</tt>
    </header>

<section>    
<h3>Abstract</h3>
<i>
ABSTRACT

Goal: This study aimed to compare the responses of three different large language models (LLMs) when presented with a simple arithmetic question: "What is 2 + 2?"

Approach: We queried three LLMs - GPT-4o-mini, Claude Sonnet 4.5, and Meta Llama 3.1 8B Instruct Turbo - with the identical prompt "What is 2 + 2?" using zero temperature to ensure deterministic responses. The responses were collected and compared for correctness and presentation style.

Findings: All three models correctly answered that 2 + 2 equals 4, achieving 100% accuracy on this basic arithmetic task. The models differed slightly in their response formatting: GPT-4o-mini used "equals," Claude Sonnet used the mathematical symbol "=," and Llama 3.1 used "is." All responses were concise and direct.

Significance: This experiment provides only a very limited assessment of basic arithmetic capabilities across three LLMs on a single trivial problem. The results cannot be generalized to more complex mathematical reasoning, multi-step problems, or other arithmetic operations. The unanimous correct response on this elementary question (2 + 2) provides no discriminative information about the relative capabilities of these models. More comprehensive testing across a range of difficulty levels and problem types would be required to draw meaningful conclusions about mathematical competence.
</i>
</section>
    

<section>
<h2>Introduction</h2>
INTRODUCTION

Large language models (LLMs) have become increasingly prevalent in applications requiring numerical and mathematical reasoning. Understanding how different models handle even the most basic arithmetic operations is a foundational step in evaluating their capabilities. This study was motivated by the need to establish a baseline comparison of how three popular LLMs respond to elementary arithmetic questions.

We conducted a minimal comparison study by presenting three LLMs - GPT-4o-mini, Claude Sonnet 4.5, and Meta Llama 3.1 8B Instruct Turbo - with the simplest possible arithmetic question: "What is 2 + 2?" Each model was queried once with identical prompts at zero temperature to ensure deterministic responses.

All three models correctly answered that 2 + 2 equals 4, with minor variations in response formatting. However, this finding is extremely limited in scope. The experiment tested only a single, trivial arithmetic problem that is likely overrepresented in training data for all modern LLMs. Success on this task provides no evidence of genuine mathematical reasoning ability, robustness to problem variations, or performance on more challenging arithmetic. The results should not be interpreted as indicative of general mathematical competence or reliability of these models for real-world applications requiring numerical reasoning.
</section>

<section>
  <h2>Approach</h2>
APPROACH

We selected three large language models representing different model families and providers:

1. GPT-4o-mini - OpenAI's compact GPT-4 variant
2. Claude Sonnet 4.5 (claude-sonnet-4-5-20250929) - Anthropic's Claude model
3. Meta Llama 3.1 8B Instruct Turbo (together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo) - Meta's open-source model accessed via Together AI

The experimental procedure was as follows:

Prompt Design: We used a single, direct prompt for all models: "What is 2 + 2?" No additional context, instructions, or formatting guidance was provided.

Query Parameters: Each model was queried with temperature set to 0 to ensure deterministic, reproducible responses. This eliminates randomness in the generation process.

Data Collection: We issued one query to each model and recorded the complete text response. No preprocessing or post-processing of responses was performed.

Analysis: Responses were compared for (1) correctness of the numerical answer and (2) stylistic differences in how the answer was presented.

Limitations: This approach tests only a single problem instance with no repetition, no variation in prompt phrasing, and no exploration of the models' uncertainty or reasoning processes. The problem selected is trivial and likely appears frequently in training data.
</section>

<section>
  <h2>Results</h2>
  <pre>
    RESULTS

We queried three LLMs with the question "What is 2 + 2?" and recorded their responses. Table 1 shows the complete response from each model.


Table 1: LLM Responses to "What is 2 + 2?"

Model                                                      Response
--------------------------------------------------------------------------------
gpt-4o-mini                                                2 + 2 equals 4.
claude-sonnet-4-5-20250929                                 2 + 2 = 4
together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo    2 + 2 is 4.


All three models provided the correct numerical answer of 4. The responses differed in formatting: GPT-4o-mini used the word "equals" in a complete sentence, Claude Sonnet used mathematical notation with the equals sign "=", and Llama 3.1 used the word "is" in a complete sentence.

Table 2 summarizes the overall statistics from this experiment.


Table 2: Summary Statistics

Metric                              Value
--------------------------------------------------------------------------------
Number of LLMs tested               3
Number giving correct answer (4)    3
Accuracy rate                       100%


The 100% accuracy rate reflects that all models correctly identified the sum of 2 + 2 as 4 on this single test instance.
    </pre>
</section>

<section>
<h2>Analysis</h2>
ANALYSIS

The experimental results reveal that all three models correctly solved the arithmetic problem, but exhibited distinct stylistic preferences in their responses.

Response Formatting Patterns:

GPT-4o-mini produced a formal, complete sentence response. When presented with the prompt "What is 2 + 2?", the model responded: "2 + 2 equals 4." This response uses the formal mathematical term "equals" and includes a period, creating a grammatically complete sentence structure.

Claude Sonnet 4.5 adopted a mathematical notation style. For the same prompt "What is 2 + 2?", it responded: "2 + 2 = 4" This is the most concise response, using the mathematical equals sign "=" rather than a verbal equivalent, and omitting punctuation. This format resembles how the answer might be written in a mathematical context.

Meta Llama 3.1 8B Instruct Turbo used an informal, conversational style. Given the prompt "What is 2 + 2?", it responded: "2 + 2 is 4." This response employs the casual verb "is" rather than "equals" and includes a period for sentence completion, making it sound more conversational than GPT-4o-mini's response.

Correctness Assessment:

All three models arrived at the numerically correct answer of 4. However, this unanimous success on such an elementary problem provides minimal discriminative information. The question "What is 2 + 2?" represents one of the most basic arithmetic facts, likely appearing countless times in each model's training data. Success on this problem does not indicate that the models possess robust arithmetic capabilities, can handle multi-step calculations, or would succeed on less common arithmetic problems.

Limitations of Analysis:

The observed stylistic differences may reflect training preferences, instruction-tuning approaches, or system prompts rather than fundamental differences in mathematical reasoning. With only a single test case, we cannot determine whether these formatting preferences are consistent across different problems. Additionally, we cannot assess whether the models have any uncertainty about their answers, whether they can explain their reasoning, or how they would perform on even slightly more complex variations such as "What is 2.0 + 2.0?" or "What is two plus two?"
</section>

<section>
<h2>Conclusion</h2>
CONCLUSIONS

This study compared three large language models - GPT-4o-mini, Claude Sonnet 4.5, and Meta Llama 3.1 8B Instruct Turbo - on their responses to the arithmetic question "What is 2 + 2?"

Main Findings:

1. All three models correctly identified that 2 + 2 equals 4, achieving 100% accuracy on this single test instance.

2. The models exhibited different response formatting styles: GPT-4o-mini used formal language ("equals"), Claude Sonnet used mathematical notation ("="), and Llama 3.1 used informal language ("is").

3. No model demonstrated any difficulty with this elementary arithmetic problem.

Critical Limitations:

The scope of this experiment is extremely narrow and the conclusions that can be drawn are correspondingly limited. We tested only one problem - arguably the most trivial arithmetic question possible - with no repetition, no variations, and no exploration of edge cases. The unanimous correct response provides no basis for distinguishing the mathematical capabilities of these models.

This experiment does NOT demonstrate that these models are reliable for arithmetic tasks in general, possess genuine mathematical reasoning abilities, or would perform correctly on more complex problems. The tested problem is so basic and likely so prevalent in training data that success provides almost no information about real-world mathematical competence.

Any application requiring dependable arithmetic or mathematical reasoning would need substantially more comprehensive testing across diverse problem types, difficulty levels, and problem formulations before any of these models could be considered trustworthy for such purposes.
</section>



<h3>Notes</h3>
claude-sonnet-4-5-20250929: 42598 tokens
Runtime: 1 minutes.




